{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a345a3a2-0d77-4801-99f7-a2c2480b525a",
   "metadata": {},
   "source": [
    "The idea now:\n",
    "Since their implementation of the model requires packages only available for a linux engine, I will have to retrofit their model to work on my computer.\n",
    "\n",
    "For the SingleStream network I need:\n",
    "- Visual Encoder:\n",
    "    - S3D Backbone 1-4 blocks, outputs S3D features (T/4x843) --> these features are used for the head network                    CHECK\n",
    "    - Head network, outputs Gloss representations in high dim space (T/4x512) --> These are the features sent forward to the S2T  CHECK\n",
    "        - Linear/BN/ReLU                                                                                                          CHECK\n",
    "        - Temporal Cov Block                                                                                                      CHECK\n",
    "    - Linear classifier, outputs Gloss logits (T/4xK)                                                                             CHECK\n",
    "    - Softmax, outputs gloss probabilities (T/4xK)                                                                                CHECK\n",
    "    - and then the CTC (connectionist temporal classification) loss and the CTC Decoder (which outputs Gloss Predictions)\n",
    "\n",
    "- Pretraining of the Visual Encoder (not necessary since we will be using their pretrained weights).\n",
    "\n",
    "- V-L Mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7289d8f-458f-44d4-b876-03a92331868f",
   "metadata": {},
   "source": [
    "### UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c413f1ad-b54a-4685-a105-c24974c3e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "from sys import platform\n",
    "from logging import Logger\n",
    "from typing import Callable, Optional\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torchinfo import summary\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import yaml\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def neq_load_customized(model, pretrained_dict, verbose=False):\n",
    "    ''' load pre-trained model in a not-equal way,\n",
    "    when new model has been partially modified '''\n",
    "    model_dict = model.state_dict()\n",
    "    tmp = {}\n",
    "    if verbose:\n",
    "        print(list(model_dict.keys()))\n",
    "        print('\\n=======Check Weights Loading======')\n",
    "        print('Weights not used from pretrained file:')\n",
    "    for k, v in pretrained_dict.items():\n",
    "        if k in model_dict and model_dict[k].shape==v.shape:\n",
    "            tmp[k] = v\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(k)\n",
    "    if verbose:\n",
    "        print('---------------------------')\n",
    "        print('Weights not loaded into new model:')\n",
    "        for k, v in model_dict.items():\n",
    "            if k not in pretrained_dict:\n",
    "                print(k)\n",
    "            elif model_dict[k].shape != pretrained_dict[k].shape:\n",
    "                print(k, 'shape mis-matched, not loaded')\n",
    "        print('===================================\\n')\n",
    "\n",
    "    del pretrained_dict\n",
    "    model_dict.update(tmp)\n",
    "    del tmp\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_logger():\n",
    "    return Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa12888-bc1a-4558-9781-00bc0d5d5c32",
   "metadata": {},
   "source": [
    "## S3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f3ec4f9e-5f8d-4992-97f5-5354a6aba873",
   "metadata": {},
   "outputs": [],
   "source": [
    "### S3D Model architecture\n",
    "\n",
    "class S3Dsup(nn.Module):\n",
    "    def __init__(self, in_channels, num_class, use_block, stride):\n",
    "        super(S3Dsup, self).__init__()\n",
    "        base_seq = []\n",
    "        if use_block>=1:\n",
    "            base_seq += [\n",
    "                SepConv3d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
    "            ]\n",
    "        if use_block>=2:\n",
    "            base_seq += [\n",
    "                nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(\n",
    "                    1, 2, 2), padding=(0, 1, 1)),                        # 1\n",
    "                BasicConv3d(64, 64, kernel_size=1, stride=1),            # 2\n",
    "                SepConv3d(64, 192, kernel_size=3, stride=1, padding=1),  # 3\n",
    "            ]\n",
    "        if use_block>=3:\n",
    "            base_seq += [\n",
    "                nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(\n",
    "                    1, 2, 2), padding=(0, 1, 1)),                        # 4\n",
    "                Mixed_3b(),                                              # 5\n",
    "                Mixed_3c(),                                              # 6\n",
    "            ]\n",
    "        if use_block>=4:\n",
    "            base_seq += [\n",
    "                nn.MaxPool3d(kernel_size=(3, 3, 3), stride=(\n",
    "                    2, 2, 2), padding=(1, 1, 1)),                        # 7\n",
    "                Mixed_4b(),                                              # 8\n",
    "                Mixed_4c(),                                              # 9\n",
    "                Mixed_4d(),                                              # 10\n",
    "                Mixed_4e(),                                              # 11\n",
    "                Mixed_4f(),                                              # 12\n",
    "            ]\n",
    "        if use_block>=5:\n",
    "            base_seq += [\n",
    "                nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(\n",
    "                    stride, 2, 2), padding=(0 if stride==2 else 1, 0, 0)),\n",
    "                Mixed_5b(),\n",
    "                Mixed_5c(), #15\n",
    "            ]\n",
    "        self.base_num_layers = len(base_seq)\n",
    "        self.base = nn.Sequential(*base_seq)\n",
    "        #self.fc = nn.Sequential(nn.Conv3d(BLOCK2SIZE[use_block], num_class, kernel_size=1, stride=1, bias=True)) \n",
    "        # Took the standard fc from S3D class pytorch, allows the model to load the weights, so we assume it's the right one\n",
    "        # 1024 for kinetics, 832 for gloss since different blocksize\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.base(x)\n",
    "        y = F.avg_pool3d(y, (2, y.size(3), y.size(4)), stride=1)\n",
    "        #y = self.fc(y)\n",
    "        y = y.view(y.size(0), y.size(1), y.size(2))\n",
    "        logits = torch.mean(y, 2)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class BasicConv3d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super(BasicConv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.bn = nn.BatchNorm3d(out_planes, eps=1e-3, momentum=0.001, affine=True)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class SepConv3d(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super(SepConv3d, self).__init__()\n",
    "        self.conv_s = nn.Conv3d(in_planes, out_planes, kernel_size=(1,kernel_size,kernel_size), stride=(1,stride,stride), padding=(0,padding,padding), bias=False)\n",
    "        self.bn_s = nn.BatchNorm3d(out_planes, eps=1e-3, momentum=0.001, affine=True)\n",
    "        self.relu_s = nn.ReLU()\n",
    "\n",
    "        self.conv_t = nn.Conv3d(out_planes, out_planes, kernel_size=(kernel_size,1,1), stride=(stride,1,1), padding=(padding,0,0), bias=False)\n",
    "        self.bn_t = nn.BatchNorm3d(out_planes, eps=1e-3, momentum=0.001, affine=True)\n",
    "        self.relu_t = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_s(x)\n",
    "        x = self.bn_s(x)\n",
    "        x = self.relu_s(x)\n",
    "\n",
    "        x = self.conv_t(x)\n",
    "        x = self.bn_t(x)\n",
    "        x = self.relu_t(x)\n",
    "        return x\n",
    "\n",
    "class Mixed_3b(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_3b, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(192, 64, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(192, 96, kernel_size=1, stride=1),\n",
    "            SepConv3d(96, 128, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(192, 16, kernel_size=1, stride=1),\n",
    "            SepConv3d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(192, 32, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_3c(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_3c, self).__init__()\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(256, 128, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(256, 128, kernel_size=1, stride=1),\n",
    "            SepConv3d(128, 192, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(256, 32, kernel_size=1, stride=1),\n",
    "            SepConv3d(32, 96, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(256, 64, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4b(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_4b, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(480, 192, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(480, 96, kernel_size=1, stride=1),\n",
    "            SepConv3d(96, 208, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(480, 16, kernel_size=1, stride=1),\n",
    "            SepConv3d(16, 48, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(480, 64, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4c(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_4c, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(512, 160, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(512, 112, kernel_size=1, stride=1),\n",
    "            SepConv3d(112, 224, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(512, 24, kernel_size=1, stride=1),\n",
    "            SepConv3d(24, 64, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(512, 64, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_4d, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(512, 128, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(512, 128, kernel_size=1, stride=1),\n",
    "            SepConv3d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(512, 24, kernel_size=1, stride=1),\n",
    "            SepConv3d(24, 64, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(512, 64, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4e(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_4e, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(512, 112, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(512, 144, kernel_size=1, stride=1),\n",
    "            SepConv3d(144, 288, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(512, 32, kernel_size=1, stride=1),\n",
    "            SepConv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(512, 64, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4f(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_4f, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(528, 256, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(528, 160, kernel_size=1, stride=1),\n",
    "            SepConv3d(160, 320, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(528, 32, kernel_size=1, stride=1),\n",
    "            SepConv3d(32, 128, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(528, 128, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_5b(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_5b, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(832, 256, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(832, 160, kernel_size=1, stride=1),\n",
    "            SepConv3d(160, 320, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(832, 32, kernel_size=1, stride=1),\n",
    "            SepConv3d(32, 128, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(832, 128, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_5c(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed_5c, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv3d(832, 384, kernel_size=1, stride=1),\n",
    "        )\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv3d(832, 192, kernel_size=1, stride=1),\n",
    "            SepConv3d(192, 384, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv3d(832, 48, kernel_size=1, stride=1),\n",
    "            SepConv3d(48, 128, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=1, padding=1),\n",
    "            BasicConv3d(832, 128, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "737e58dc-cf68-4eb0-afb9-d908dd59d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize S3D\n",
    "\n",
    "BLOCK2SIZE = {1:64, 2:192, 3:480, 4:832, 5:1024}\n",
    "\n",
    "class S3Ds(S3Dsup):\n",
    "    def __init__(self, num_class=400, in_channel=3, use_block=5, freeze_block=0, stride=2):  # 5 and 0 for kinetics, 4 and 1 for gloss\n",
    "        self.use_block = use_block\n",
    "        super(S3Ds, self).__init__(in_channels=in_channel, num_class=num_class, use_block=use_block, stride=stride)\n",
    "        self.freeze_block = freeze_block\n",
    "        self.END_POINT2BLOCK = {\n",
    "            0: 'block1',\n",
    "            3: 'block2',\n",
    "            6: 'block3',\n",
    "            12: 'block4',\n",
    "            15: 'block5',\n",
    "        }\n",
    "        self.BLOCK2END_POINT = {blk:ep for ep, blk in self.END_POINT2BLOCK.items()}\n",
    "\n",
    "        self.frozen_modules = []\n",
    "        self.use_block = use_block\n",
    "\n",
    "        if freeze_block>0:\n",
    "            for i in range(0, self.base_num_layers): #base  0,1,2,...,self.BLOCK2END_POINT[blk]\n",
    "                module_name = 'base.{}'.format(i)\n",
    "                submodule = self.base[i]\n",
    "                assert submodule != None, module_name\n",
    "                if i <= self.BLOCK2END_POINT['block{}'.format(freeze_block)]:\n",
    "                    self.frozen_modules.append(submodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7751474-8c25-4b24-8d24-e9d740a63556",
   "metadata": {},
   "source": [
    "## Head network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e219ffdf-ff0d-4d91-b662-7fca1b589fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 832])\n",
      "{'name': 'test/10March_2011_Thursday_heute-58', 'gloss': 'WOCHENENDE SONNE SAMSTAG SCHOEN TEMPERATUR BIS SIEBZEHN GRAD REGION', 'text': 'sonnig geht es auch ins wochenende samstag ein herrlicher tag mit temperaturen bis siebzehn grad hier im westen .', 'num_frames': 130, 'sign': tensor([[2.7592e-36, 0.0000e+00, 2.3513e-36,  ..., 1.3635e-02, 7.4006e-02,\n",
      "         1.2359e-01],\n",
      "        [2.7592e-36, 0.0000e+00, 2.3513e-36,  ..., 9.0310e-04, 8.9023e-02,\n",
      "         2.2051e-01],\n",
      "        [2.7592e-36, 0.0000e+00, 2.3513e-36,  ..., 1.1407e-04, 8.9353e-02,\n",
      "         2.4418e-01],\n",
      "        ...,\n",
      "        [2.7592e-36, 0.0000e+00, 2.3513e-36,  ..., 4.1541e-02, 7.7600e-02,\n",
      "         8.1139e-02],\n",
      "        [2.7592e-36, 0.0000e+00, 2.3513e-36,  ..., 3.9211e-02, 7.4247e-02,\n",
      "         5.1760e-02],\n",
      "        [2.7592e-36, 0.0000e+00, 2.3513e-36,  ..., 3.2588e-02, 6.8302e-02,\n",
      "         4.3865e-02]])}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with gzip.open(\"SLRTNGT/TwoStreamNetwork/experiments/outputs/SingleStream/head_rgb_input/test.pkl\", 'rb') as f:\n",
    "                    split_data = pickle.load(f)\n",
    "\n",
    "print(split_data[3]['sign'].shape)\n",
    "\n",
    "print(split_data[3])\n",
    "\n",
    "## So we know the extracted features are only from the S3D, since the size is (number of frames)/4 by 832, \n",
    "## the input for the head are T (num frames/4) by 843\n",
    "## so the head input size varies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "140ff4c1-8db8-4696-b149-589aa4cf5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from SLRTNGT.TwoStreamNetwork.utils.misc import get_logger\n",
    "from SLRTNGT.TwoStreamNetwork.modelling.utils import PositionalEncoding, MaskedNorm, PositionwiseFeedForward, MLPHead\n",
    "\n",
    "#testing:\n",
    "#  cfg:\n",
    "#    recognition:\n",
    "#      beam_size: 5\n",
    "\n",
    "#model:\n",
    "#  RecognitionNetwork:\n",
    "#    GlossTokenizer:\n",
    "#      gloss2id_file: data/csl-daily/gloss2ids.pkl\n",
    "#    s3d:\n",
    "#      pretrained_ckpt: pretrained_models/s3ds_glosscls_ckpt\n",
    "#      use_block: 4\n",
    "#      freeze_block: 1\n",
    "#    visual_head:\n",
    "#      input_size: 832\n",
    "#      hidden_size: 512\n",
    "#      ff_size: 2048 \n",
    "#      pe: True\n",
    "#      ff_kernelsize:\n",
    "#        - 3\n",
    "#        - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f15bda4a-f043-4d40-95fc-2bc0ed4e9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualHead(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "        cls_num, input_size=832, hidden_size=512, ff_size=2048, pe=True,\n",
    "        ff_kernelsize=3, pretrained_ckpt=None, is_empty=False, frozen=False, \n",
    "        plus_conv_cfg={},\n",
    "        ssl_projection_cfg={}):\n",
    "        super().__init__()\n",
    "        self.is_empty = is_empty\n",
    "        self.plus_conv_cfg = plus_conv_cfg\n",
    "        self.ssl_projection_cfg = ssl_projection_cfg\n",
    "        if is_empty==False:\n",
    "            self.frozen = frozen\n",
    "            self.hidden_size = hidden_size\n",
    "\n",
    "            if input_size is None:\n",
    "                self.fc1 = nn.Identity()\n",
    "            else:\n",
    "                self.fc1 = torch.nn.Linear(input_size, self.hidden_size)\n",
    "            self.bn1 = MaskedNorm(num_features=self.hidden_size, norm_type='sync_batch')\n",
    "            self.relu1 = torch.nn.ReLU()\n",
    "            self.dropout1 = torch.nn.Dropout(p=0.1)\n",
    "\n",
    "            if pe:\n",
    "                self.pe = PositionalEncoding(self.hidden_size)\n",
    "            else:\n",
    "                self.pe = torch.nn.Identity()\n",
    "\n",
    "            self.feedforward = PositionwiseFeedForward(input_size=self.hidden_size,\n",
    "                ff_size=ff_size,\n",
    "                dropout=0.1, kernel_size=ff_kernelsize, skip_connection=True)\n",
    "            \n",
    "            self.layer_norm = torch.nn.LayerNorm(self.hidden_size, eps=1e-6)\n",
    "\n",
    "            if plus_conv_cfg!={}:\n",
    "                plus_convs = []\n",
    "                for i in range(plus_conv_cfg['num_layer']):\n",
    "                    plus_convs.append(nn.Conv1d(self.hidden_size, self.hidden_size, \n",
    "                        kernel_size=plus_conv_cfg['kernel_size'], stride=plus_conv_cfg['stride'], padding_mode='replicate'))\n",
    "                self.plus_conv = nn.Sequential(*plus_convs)\n",
    "            else:\n",
    "                self.plus_conv = nn.Identity()\n",
    "\n",
    "            if ssl_projection_cfg!={}:\n",
    "                self.ssl_projection = MLPHead(embedding_size=self.hidden_size, \n",
    "                    projection_hidden_size=ssl_projection_cfg['hidden_size'])\n",
    "\n",
    "            self.gloss_output_layer = torch.nn.Linear(self.hidden_size, cls_num)\n",
    "\n",
    "            if self.frozen:\n",
    "                self.frozen_layers = [self.fc1, self.bn1, self.relu1,  self.pe, self.dropout1, self.feedforward, self.layer_norm]\n",
    "                for layer in self.frozen_layers:\n",
    "                    for name, param in layer.named_parameters():\n",
    "                        param.requires_grad = False\n",
    "                    layer.eval()\n",
    "        else:\n",
    "            self.gloss_output_layer = torch.nn.Linear(input_size, cls_num)\n",
    "        if pretrained_ckpt:\n",
    "            self.load_from_pretrained_ckpt(pretrained_ckpt)\n",
    "\n",
    "    def load_from_pretrained_ckpt(self, pretrained_ckpt):\n",
    "        logger = Logger     # get_logger()\n",
    "        checkpoint = torch.load(pretrained_ckpt, map_location='cpu')#['model_state']\n",
    "        load_dict = {}\n",
    "        for k,v in checkpoint.items():\n",
    "            if 'recognition_network.visual_head.' in k:\n",
    "                load_dict[k.replace('recognition_network.visual_head.','')] = v\n",
    "        self.load_state_dict(load_dict)\n",
    "        logger.info('Load Visual Head from pretrained ckpt {}'.format(pretrained_ckpt))\n",
    "\n",
    "    def forward(self, x, mask, valid_len_in=None):\n",
    "        B, Tin, D = x.shape \n",
    "        if self.is_empty==False:\n",
    "            if not self.frozen:\n",
    "                #projection 1\n",
    "                x = self.fc1(x)\n",
    "                x = self.bn1(x, mask)\n",
    "                x = self.relu1(x)\n",
    "                #pe\n",
    "                x = self.pe(x)\n",
    "                x = self.dropout1(x)\n",
    "\n",
    "                #feedforward\n",
    "                x = self.feedforward(x)\n",
    "                x = self.layer_norm(x)\n",
    "\n",
    "                x = x.transpose(1,2)\n",
    "                x = self.plus_conv(x)\n",
    "                x = x.transpose(1,2)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    for ii, layer in enumerate(self.frozen_layers):\n",
    "                        layer.eval()\n",
    "                        if ii==1:\n",
    "                            x = layer(x, mask)\n",
    "                        else:\n",
    "                            x = layer(x)\n",
    "                x = x.transpose(1,2)\n",
    "                x = self.plus_conv(x)\n",
    "                x = x.transpose(1,2)\n",
    "\n",
    "        #classification\n",
    "        logits = self.gloss_output_layer(x) #B,T,V\n",
    "\n",
    "        #softmax\n",
    "        gloss_probabilities_log = logits.log_softmax(2) \n",
    "        gloss_probabilities = logits.softmax(2)\n",
    "\n",
    "        if self.plus_conv_cfg!={}:\n",
    "            B, Tout, D = x.shape\n",
    "            valid_len_out = torch.floor(valid_len_in*Tout/Tin).long() #B,\n",
    "        else:\n",
    "            valid_len_out = valid_len_in\n",
    "        if self.ssl_projection_cfg!={}:\n",
    "            x_ssl = self.ssl_projection(x)\n",
    "            if self.ssl_projection_cfg['normalize']==True:\n",
    "                x_ssl = F.normalize(x_ssl, dim=-1)\n",
    "        else:\n",
    "            x_ssl = None\n",
    "\n",
    "        ## These are all the different features we can use\n",
    "        return {'gloss_feature_ssl':x_ssl, \n",
    "                'gloss_feature': x,\n",
    "                'gloss_feature_norm': F.normalize(x, dim=-1),\n",
    "                'gloss_logits':logits, \n",
    "                'gloss_probabilities_log':gloss_probabilities_log,\n",
    "                'gloss_probabilities': gloss_probabilities,\n",
    "                'valid_len_out':valid_len_out}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce55d3-2915-41b9-93c4-33096b20ca4e",
   "metadata": {},
   "source": [
    "#### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "61f4b6fe-02a6-4bf9-929e-e1073516ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2000\n",
      "loading weight file\n",
      " name? model_state\n",
      " loaded\n",
      "torch.Size([1, 3, 9, 270, 270])\n",
      "\n",
      "The features outputted by pretrained S3D\n",
      "tensor([[1.3838e-12, 0.0000e+00, 5.1434e-08, 3.1768e-06, 0.0000e+00, 0.0000e+00,\n",
      "         3.9563e-07, 5.3867e-07, 1.7031e-09, 1.2489e-06, 1.6452e-06, 0.0000e+00,\n",
      "         1.5541e-07, 7.2978e-07, 2.1194e-06, 1.2691e-06, 2.9470e-06, 0.0000e+00,\n",
      "         3.8539e-09, 1.8049e-06, 1.8538e-06, 2.1831e-06, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 3.0256e-07, 2.5964e-06, 6.4925e-06, 1.0622e-06, 0.0000e+00,\n",
      "         2.6224e-06, 0.0000e+00, 0.0000e+00, 1.1861e-06, 5.7402e-06, 6.9225e-08,\n",
      "         0.0000e+00, 5.8346e-07, 1.1322e-07, 1.5413e-06, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0068e-07,\n",
      "         0.0000e+00, 2.7371e-06, 0.0000e+00, 5.4820e-07, 1.7476e-06, 0.0000e+00,\n",
      "         3.9122e-06, 2.6886e-06, 1.6636e-06, 2.9926e-07, 5.0782e-06, 1.9773e-10,\n",
      "         3.2010e-06, 2.4459e-06, 0.0000e+00, 1.2536e-06, 0.0000e+00, 3.2941e-06,\n",
      "         2.2584e-08, 2.6837e-06, 2.8861e-06, 1.1916e-07, 6.8909e-08, 5.7618e-06,\n",
      "         1.4971e-07, 5.0034e-06, 2.6136e-06, 2.4452e-06, 3.5775e-06, 0.0000e+00,\n",
      "         9.2965e-07, 0.0000e+00, 0.0000e+00, 3.2890e-06, 1.6313e-08, 9.4991e-07,\n",
      "         9.2692e-07, 9.1815e-10, 0.0000e+00, 1.1746e-06, 9.6747e-07, 6.7971e-07,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4582e-06, 1.5192e-08, 5.7737e-09,\n",
      "         2.3872e-06, 5.9888e-08, 5.2749e-06, 3.4137e-07, 3.2175e-07, 3.3818e-06,\n",
      "         0.0000e+00, 5.7844e-06, 2.7895e-06, 1.2371e-07, 1.2770e-06, 4.9339e-08,\n",
      "         1.8360e-06, 0.0000e+00, 8.2388e-07, 0.0000e+00, 5.3260e-07, 1.1982e-08,\n",
      "         1.6058e-06, 3.8480e-06, 0.0000e+00, 9.3866e-07, 1.0017e-06, 3.3808e-06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3268e-06, 3.8469e-06, 6.2196e-06,\n",
      "         0.0000e+00, 0.0000e+00, 3.1121e-07, 0.0000e+00, 1.7851e-09, 0.0000e+00,\n",
      "         3.2272e-06, 1.2836e-06, 0.0000e+00, 4.8602e-06, 2.5199e-07, 1.7942e-06,\n",
      "         5.2324e-06, 6.2673e-07, 7.8894e-06, 5.0517e-06, 0.0000e+00, 1.2711e-07,\n",
      "         0.0000e+00, 6.0484e-09, 8.6303e-08, 3.0840e-07, 0.0000e+00, 0.0000e+00,\n",
      "         1.9327e-07, 0.0000e+00, 6.4202e-06, 3.5452e-06, 1.0005e-06, 1.2557e-08,\n",
      "         0.0000e+00, 5.3191e-06, 6.2138e-06, 0.0000e+00, 3.5448e-06, 3.4626e-06,\n",
      "         2.1883e-07, 0.0000e+00, 1.2125e-06, 3.1536e-06, 2.3325e-06, 0.0000e+00,\n",
      "         5.3384e-08, 4.1275e-06, 1.1041e-10, 3.3243e-06, 2.0810e-06, 2.6241e-06,\n",
      "         1.6135e-06, 0.0000e+00, 0.0000e+00, 4.9637e-10, 0.0000e+00, 1.8457e-08,\n",
      "         4.1909e-06, 0.0000e+00, 2.7166e-06, 1.1605e-07, 1.5073e-06, 0.0000e+00,\n",
      "         0.0000e+00, 3.1180e-06, 6.4179e-06, 2.3171e-06, 3.2062e-06, 1.3172e-07,\n",
      "         3.5757e-06, 1.0982e-08, 0.0000e+00, 0.0000e+00, 1.7184e-07, 2.9230e-07,\n",
      "         6.0124e-06, 3.5229e-06, 2.0398e-06, 1.3106e-06, 1.9626e-06, 2.7372e-06,\n",
      "         8.9544e-10, 2.6141e-06, 4.5913e-06, 9.7193e-07, 0.0000e+00, 0.0000e+00,\n",
      "         2.4228e-07, 1.2529e-06, 8.5124e-07, 3.3001e-07, 6.2005e-08, 2.6817e-06,\n",
      "         1.0056e-07, 2.8647e-06, 5.8073e-09, 0.0000e+00, 2.6750e-07, 0.0000e+00,\n",
      "         6.0734e-06, 0.0000e+00, 6.5491e-06, 0.0000e+00, 0.0000e+00, 2.9996e-07,\n",
      "         4.9689e-07, 0.0000e+00, 0.0000e+00, 5.9605e-07, 1.0469e-07, 4.8006e-08,\n",
      "         0.0000e+00, 3.4537e-08, 4.6198e-06, 0.0000e+00, 3.9343e-07, 0.0000e+00,\n",
      "         4.6545e-06, 5.5568e-07, 0.0000e+00, 5.1509e-09, 1.0086e-08, 7.3553e-08,\n",
      "         3.7356e-06, 4.5301e-06, 1.4886e-07, 1.7743e-06, 5.1962e-07, 2.4138e-09,\n",
      "         0.0000e+00, 2.1018e-07, 0.0000e+00, 0.0000e+00, 7.2613e-09, 4.5065e-09,\n",
      "         4.0955e-07, 6.4947e-09, 3.1679e-07, 3.4175e-07, 3.3310e-09, 4.8945e-08,\n",
      "         2.7871e-07, 1.4841e-08, 3.8304e-08, 7.0986e-07, 3.6636e-07, 9.2109e-08,\n",
      "         3.9269e-07, 1.5955e-07, 4.6578e-08, 5.3060e-08, 2.8471e-07, 1.3277e-10,\n",
      "         3.1739e-07, 1.3238e-06, 7.8053e-08, 5.9834e-10, 4.7017e-07, 1.2268e-09,\n",
      "         4.4425e-07, 1.7654e-08, 2.6792e-08, 3.0192e-07, 6.9898e-10, 5.0438e-07,\n",
      "         1.0531e-07, 3.8253e-09, 1.9469e-07, 8.6133e-07, 1.1327e-06, 0.0000e+00,\n",
      "         4.4606e-07, 2.8057e-09, 2.3568e-07, 5.0967e-11, 1.7286e-08, 5.8300e-09,\n",
      "         4.5000e-09, 1.2256e-09, 3.3488e-08, 2.3370e-09, 1.0574e-07, 0.0000e+00,\n",
      "         0.0000e+00, 1.5927e-07, 6.3205e-09, 1.1276e-09, 5.5320e-07, 2.2935e-07,\n",
      "         2.2603e-10, 1.0920e-06, 0.0000e+00, 2.6018e-08, 3.6881e-08, 7.7660e-11,\n",
      "         6.6210e-07, 1.6155e-11, 1.1224e-09, 1.2355e-08, 7.6865e-07, 2.4473e-07,\n",
      "         6.7566e-09, 4.8836e-07, 1.3632e-07, 4.3803e-07, 1.1771e-10, 9.6242e-08,\n",
      "         6.6713e-08, 7.9717e-08, 1.7555e-08, 1.7590e-07, 2.6954e-08, 4.9101e-08,\n",
      "         1.5889e-08, 2.4404e-07, 2.7565e-10, 3.4229e-07, 3.5602e-07, 4.8706e-07,\n",
      "         2.9176e-07, 6.0105e-09, 5.3205e-07, 1.0271e-10, 5.3592e-08, 1.1693e-07,\n",
      "         5.5837e-08, 8.5556e-08, 5.7092e-08, 6.3153e-08, 1.9249e-07, 9.4773e-07,\n",
      "         0.0000e+00, 7.2610e-08, 1.3913e-09, 4.7787e-07, 6.1712e-08, 6.3160e-08,\n",
      "         7.5072e-07, 3.7467e-07, 6.9562e-08, 7.5021e-08, 1.5635e-10, 4.9927e-09,\n",
      "         7.0706e-08, 7.3888e-08, 6.7513e-07, 3.6270e-09, 5.2631e-07, 0.0000e+00,\n",
      "         3.4168e-07, 1.0481e-06, 1.2084e-08, 0.0000e+00, 2.6916e-07, 7.5716e-08,\n",
      "         2.8757e-11, 7.3034e-10, 0.0000e+00, 7.8857e-08, 8.2248e-07, 1.5622e-07,\n",
      "         2.2477e-07, 4.9817e-11, 2.7853e-07, 3.7779e-07, 8.3592e-08, 9.0348e-10,\n",
      "         1.5962e-08, 2.5181e-07, 0.0000e+00, 2.4318e-07, 4.6117e-07, 4.8822e-09,\n",
      "         7.3698e-08, 7.4533e-08, 1.5017e-07, 4.8272e-08, 9.6246e-10, 3.0106e-07,\n",
      "         7.8371e-07, 3.7176e-09, 2.0455e-09, 3.3239e-07, 1.1631e-08, 8.0229e-07,\n",
      "         8.7841e-07, 6.1859e-08, 2.1531e-08, 4.9484e-07, 1.2914e-07, 3.5754e-09,\n",
      "         6.7450e-08, 2.6990e-08, 2.6960e-07, 3.5855e-08, 4.5124e-07, 1.4386e-07,\n",
      "         1.0456e-07, 1.9731e-07, 1.4609e-08, 3.2374e-07, 5.0846e-08, 2.8846e-07,\n",
      "         3.3505e-07, 8.0244e-10, 5.0954e-08, 1.3167e-07, 4.2232e-08, 2.5263e-09,\n",
      "         4.8126e-07, 1.7053e-10, 5.4972e-08, 6.2385e-07, 3.8287e-07, 2.4310e-08,\n",
      "         3.8639e-07, 2.2982e-08, 3.3805e-07, 4.4510e-07, 1.0637e-08, 5.9534e-09,\n",
      "         1.0617e-07, 3.8099e-08, 1.9649e-10, 1.2675e-08, 6.3041e-08, 0.0000e+00,\n",
      "         1.8954e-07, 4.1318e-08, 0.0000e+00, 8.2480e-10, 1.0845e-08, 1.6072e-07,\n",
      "         8.3543e-08, 1.8602e-07, 2.5392e-08, 1.1118e-07, 3.5917e-07, 4.5709e-07,\n",
      "         6.3643e-08, 5.5108e-07, 6.7110e-08, 4.8497e-07, 4.2121e-07, 1.7326e-08,\n",
      "         5.3872e-07, 2.7126e-07, 5.7324e-09, 4.3764e-11, 3.0270e-07, 4.7216e-07,\n",
      "         7.4149e-07, 8.9924e-08, 4.5148e-10, 7.1194e-07, 7.7851e-08, 2.1654e-09,\n",
      "         5.9803e-07, 5.8357e-09, 3.8362e-08, 6.3406e-08, 1.0743e-11, 8.7861e-07,\n",
      "         9.1091e-07, 2.5356e-08, 4.6077e-07, 6.9930e-11, 0.0000e+00, 6.6137e-07,\n",
      "         1.6422e-07, 3.6856e-08, 2.5600e-07, 9.1762e-07, 8.9961e-09, 2.2602e-09,\n",
      "         7.2001e-07, 7.8320e-07, 1.1264e-07, 7.2254e-09, 5.0966e-07, 3.1269e-07,\n",
      "         1.0886e-07, 4.9274e-10, 9.5888e-07, 1.8644e-07, 2.2568e-08, 3.3434e-09,\n",
      "         1.0198e-10, 0.0000e+00, 2.7302e-07, 5.1936e-07, 4.4506e-07, 2.3485e-08,\n",
      "         3.2933e-07, 2.2654e-07, 1.6782e-07, 1.4103e-09, 3.8218e-08, 2.1533e-07,\n",
      "         3.3249e-08, 1.0654e-08, 8.0091e-09, 3.4492e-07, 0.0000e+00, 1.5402e-10,\n",
      "         7.5781e-08, 2.0230e-08, 2.2138e-07, 1.7097e-08, 1.2456e-07, 0.0000e+00,\n",
      "         3.0317e-10, 2.0145e-08, 1.4698e-07, 2.7861e-08, 2.1309e-08, 1.5319e-07,\n",
      "         6.3092e-11, 7.0892e-08, 2.0716e-07, 1.8709e-09, 6.8642e-09, 3.9853e-07,\n",
      "         8.4644e-07, 1.4466e-07, 4.4249e-11, 1.8215e-09, 1.2349e-07, 3.1355e-07,\n",
      "         8.6345e-09, 7.5865e-08, 2.1035e-08, 3.3211e-08, 6.1697e-08, 3.9781e-08,\n",
      "         1.0144e-07, 2.6158e-10, 1.2344e-08, 9.5040e-11, 4.8680e-08, 1.7871e-07,\n",
      "         0.0000e+00, 1.7493e-08, 3.6469e-09, 9.1904e-09, 6.3939e-07, 3.9142e-07,\n",
      "         2.9123e-07, 5.6356e-07, 1.0124e-07, 2.7349e-07, 3.6924e-07, 5.5386e-08,\n",
      "         4.6476e-11, 1.1255e-08, 1.9375e-08, 4.5041e-08, 5.8486e-10, 7.2720e-09,\n",
      "         1.2797e-07, 5.6497e-10, 5.6968e-09, 1.0152e-07, 7.6678e-08, 2.2257e-07,\n",
      "         9.4830e-08, 1.6451e-07, 7.8489e-08, 3.9996e-08, 4.9863e-11, 3.0449e-08,\n",
      "         2.3539e-07, 8.5846e-08, 3.0443e-07, 6.2070e-08, 1.4776e-07, 1.7324e-08,\n",
      "         2.0860e-09, 2.2207e-07, 7.0364e-09, 8.2392e-08, 2.8021e-09, 2.1634e-10,\n",
      "         5.7214e-09, 4.4978e-09, 1.1385e-07, 5.0049e-07, 8.1273e-08, 2.5792e-07,\n",
      "         3.5064e-08, 4.0955e-09, 1.0754e-08, 8.3494e-09, 2.3576e-07, 1.7232e-09,\n",
      "         2.1286e-07, 2.1195e-07, 4.3144e-07, 1.2681e-07, 3.5936e-08, 1.6071e-08,\n",
      "         1.9959e-07, 8.2318e-08, 1.4321e-07, 1.8187e-08, 3.5064e-07, 5.8657e-10,\n",
      "         7.0703e-09, 1.4617e-09, 3.4766e-08, 5.4377e-09, 2.7260e-08, 1.6313e-07,\n",
      "         4.6247e-08, 3.1847e-08, 2.8828e-09, 1.9385e-09, 3.0590e-09, 3.6661e-09,\n",
      "         1.2454e-08, 4.3381e-07, 4.2529e-08, 9.6589e-08, 3.4815e-07, 3.1039e-08,\n",
      "         5.2554e-08, 3.1137e-08, 1.0044e-07, 4.4967e-07, 2.1229e-08, 1.5067e-07,\n",
      "         2.0899e-07, 4.5447e-07, 9.7707e-10, 2.5417e-07, 0.0000e+00, 8.9844e-08,\n",
      "         1.3059e-07, 7.1658e-09, 2.3211e-07, 4.6809e-09, 3.5106e-07, 1.2951e-07,\n",
      "         2.2640e-08, 3.3957e-07, 1.4961e-07, 1.7879e-07, 6.5233e-08, 3.9217e-08,\n",
      "         2.9942e-07, 9.1787e-09, 2.4834e-07, 1.4378e-07, 6.3589e-09, 3.6473e-08,\n",
      "         3.0447e-10, 1.0898e-07, 2.1263e-07, 4.6143e-09, 2.9311e-08, 2.1720e-08,\n",
      "         2.6441e-07, 4.8897e-08, 1.1636e-07, 6.3741e-08, 8.7332e-08, 1.2641e-07,\n",
      "         4.2569e-08, 1.5419e-08, 2.3229e-07, 4.2310e-08, 2.3721e-07, 5.4274e-09,\n",
      "         1.8002e-09, 1.2671e-09, 2.9555e-07, 3.2566e-08, 3.9054e-07, 0.0000e+00,\n",
      "         2.2665e-08, 2.5605e-08, 0.0000e+00, 5.6449e-06, 3.0018e-06, 0.0000e+00,\n",
      "         0.0000e+00, 1.7506e-06, 0.0000e+00, 0.0000e+00, 2.2488e-06, 1.4897e-10,\n",
      "         1.3336e-06, 5.3076e-06, 1.5423e-06, 8.4880e-09, 4.6321e-06, 1.5166e-06,\n",
      "         5.1174e-06, 0.0000e+00, 2.5288e-06, 3.8131e-07, 0.0000e+00, 0.0000e+00,\n",
      "         4.6876e-06, 1.3567e-06, 2.8956e-06, 2.5656e-06, 0.0000e+00, 0.0000e+00,\n",
      "         4.7346e-06, 0.0000e+00, 2.7109e-06, 2.7948e-06, 3.6581e-06, 2.8608e-06,\n",
      "         3.2292e-06, 2.3828e-08, 3.9655e-06, 2.9565e-06, 1.1767e-06, 3.6946e-10,\n",
      "         1.5733e-06, 1.5701e-06, 4.6530e-06, 2.1193e-07, 5.6080e-06, 1.3287e-09,\n",
      "         5.0896e-06, 0.0000e+00, 2.2019e-06, 0.0000e+00, 0.0000e+00, 7.7366e-09,\n",
      "         0.0000e+00, 0.0000e+00, 1.2264e-06, 0.0000e+00, 0.0000e+00, 1.5403e-06,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1387e-06, 1.3881e-08, 1.8793e-06,\n",
      "         0.0000e+00, 0.0000e+00, 9.5689e-08, 2.1407e-06, 2.2619e-06, 2.7201e-06,\n",
      "         2.4211e-06, 1.6406e-06, 8.7483e-09, 4.6822e-06, 0.0000e+00, 0.0000e+00,\n",
      "         1.8750e-06, 1.9352e-06, 1.9384e-07, 1.7896e-07, 0.0000e+00, 0.0000e+00,\n",
      "         2.4696e-06, 3.5149e-08, 0.0000e+00, 0.0000e+00, 1.3483e-06, 0.0000e+00,\n",
      "         0.0000e+00, 4.3735e-06, 6.8994e-08, 0.0000e+00, 0.0000e+00, 4.7042e-07,\n",
      "         0.0000e+00, 5.9125e-08, 3.5208e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.0019e-06, 1.0105e-06, 2.0708e-06, 0.0000e+00, 1.7763e-06, 4.8608e-07,\n",
      "         1.4868e-06, 4.7574e-06, 0.0000e+00, 0.0000e+00, 1.7658e-09, 3.7966e-07,\n",
      "         4.9865e-06, 3.0601e-06, 1.3993e-06, 0.0000e+00, 0.0000e+00, 3.4777e-06,\n",
      "         0.0000e+00, 4.5864e-06, 5.3793e-06, 6.4591e-06, 6.1400e-09, 0.0000e+00,\n",
      "         2.6164e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "\n",
      "\n",
      "torch.Size([1, 1, 512])\n",
      "torch.Size([1, 1, 2000])\n",
      "{'gloss_feature_ssl': None, 'gloss_feature': tensor([[[-1.1067,  1.3064, -1.0669,  1.1847, -0.9057,  0.9981, -0.6212,\n",
      "           1.0681, -0.9121,  1.2491, -0.9121,  1.0889, -1.1523,  1.0817,\n",
      "          -0.9235, -0.9990, -1.0208,  1.1389, -0.8752,  1.0908, -1.0351,\n",
      "           1.0110, -0.9984,  1.1030, -1.1018, -0.8218, -0.9433,  1.0488,\n",
      "          -0.8793,  1.1347, -1.0006,  1.1733, -1.0533,  1.0859, -0.7174,\n",
      "           1.0681, -1.0690,  0.9846, -0.6771,  1.0844, -0.7171,  1.1191,\n",
      "          -0.8144,  0.9296, -0.6685,  1.3508, -0.9329,  1.1939, -0.8519,\n",
      "           1.1127, -0.7801,  0.8154, -0.9937,  1.1605, -0.9241,  1.0895,\n",
      "          -1.0680, -1.0247, -1.1929,  0.6983, -0.9512,  1.1238, -0.8908,\n",
      "           1.0405, -0.8431,  1.0681, -0.9789,  1.0938, -0.8941,  0.9398,\n",
      "          -1.2167,  1.0720, -0.9121,  1.0040, -1.0838,  1.1000, -0.9579,\n",
      "           1.0928, -0.9121,  1.0686, -0.9121,  1.3562, -0.6464,  0.9562,\n",
      "          -0.6938,  1.1112, -0.9032,  1.0289, -0.9208, -0.7683, -0.6680,\n",
      "           1.0899, -0.7332,  0.8681, -0.9592,  1.0851, -1.0466, -0.9437,\n",
      "          -1.1069,  1.0040, -0.9455,  1.0681, -0.6956,  1.0902, -0.9497,\n",
      "           1.0742, -0.9728,  0.9188, -0.9721,  0.9752, -0.8609,  1.2898,\n",
      "          -0.8049,  0.9285, -0.6136, -0.7416, -0.8527,  0.8933, -0.8627,\n",
      "           1.2107, -0.8916,  1.1997, -0.9499,  1.2058, -1.0133,  1.0681,\n",
      "          -0.5943,  1.0237, -0.8721,  0.9704, -0.9202,  1.2903, -0.9252,\n",
      "           1.0793, -1.1104,  1.1989, -0.8795,  1.2036, -0.9121,  1.0331,\n",
      "          -0.6282,  1.1749, -0.7796,  1.1990, -0.9035,  1.1282, -0.9472,\n",
      "           1.1213, -1.0102,  1.0713, -0.8445,  1.1104, -0.8623,  1.1115,\n",
      "          -0.7959,  1.1297, -0.9462,  1.2397, -1.2439,  1.1812, -0.9071,\n",
      "           1.1794, -1.0341,  1.0854, -1.0541,  0.7243, -0.7285, -0.6295,\n",
      "          -1.1742,  1.1200, -0.7818,  1.0011, -0.9121,  0.9709, -1.3161,\n",
      "           0.9922, -0.6340,  1.1592, -1.0627,  1.0681, -0.9121,  1.0118,\n",
      "          -0.8996,  1.0569, -0.7647,  1.1131, -1.0163,  1.3477, -0.8851,\n",
      "           0.7897, -0.9093,  1.2894, -1.1599, -0.8429, -0.9576,  1.0920,\n",
      "          -0.9947,  1.1218, -0.8905,  1.0297, -0.6843,  1.0681, -1.0142,\n",
      "           1.1302, -1.1946,  1.0179, -1.1217,  1.0705, -0.7507,  0.8874,\n",
      "          -0.9276,  0.6541, -0.9005,  0.9687, -0.6491,  1.0512, -0.6333,\n",
      "           1.0734, -1.0129,  1.0091, -0.8234,  1.0659, -0.8460,  0.6663,\n",
      "          -1.1266,  1.1808, -0.6610, -0.9159, -0.9903,  0.8297, -0.6422,\n",
      "           0.9215, -1.1204,  1.1200, -0.8308,  1.1913, -0.6208,  1.3188,\n",
      "          -0.7618,  1.3704, -0.9094, -0.8812, -0.7366,  0.9785, -0.8950,\n",
      "           1.0626, -1.1143,  0.8987, -1.0644,  0.9057, -0.8096,  1.3439,\n",
      "          -0.6305,  1.0978, -0.6182,  0.9397, -1.0171,  1.0161, -0.9876,\n",
      "           1.2074, -0.9889,  1.4502, -0.8963,  1.0592, -0.9977,  0.7900,\n",
      "          -0.7160,  1.0398, -0.9039, -0.5764, -1.0139,  1.0681, -0.6465,\n",
      "           0.9794, -0.8892,  1.1650, -1.2480,  1.0813, -0.8493,  1.1012,\n",
      "          -1.1107, -0.8137, -1.0091,  1.1010, -0.7998,  0.9593, -0.9059,\n",
      "           0.9383, -0.8670,  1.0983, -0.9121,  0.9654, -0.8454,  0.8985,\n",
      "          -0.8514,  1.2511, -0.9121,  1.1102, -1.2428,  1.1274, -0.8324,\n",
      "           1.2404, -0.8619,  1.1107, -1.0732,  0.5859, -0.7486,  1.1707,\n",
      "          -0.9121,  0.8290, -0.5522,  1.3447, -0.7782,  0.9106, -0.8574,\n",
      "           1.1924, -0.9121,  1.0632, -0.8539,  1.1322, -0.8741,  1.0309,\n",
      "          -0.7186,  1.0654, -1.1348,  1.0575, -0.8540, -0.8495, -0.7730,\n",
      "           1.1330, -0.7341,  1.0803, -0.5546, -0.8851, -0.9793,  1.1852,\n",
      "          -0.9121,  1.3210, -0.7009,  1.0123, -0.6600, -0.6984, -0.7562,\n",
      "           1.2672, -0.7124,  1.0223, -0.8052,  0.8524, -0.9470,  1.4294,\n",
      "          -0.6368,  1.5873, -0.9828,  1.0718, -1.0899, -0.7880, -0.9121,\n",
      "           1.2939, -0.9402,  1.0894, -0.8909,  1.1646, -0.9121,  1.0685,\n",
      "          -0.6712,  0.8961, -0.5229, -0.9121, -1.1147,  1.0640, -0.8361,\n",
      "           1.0920, -0.5765,  0.9745, -1.1485,  1.2224, -0.5861,  1.1507,\n",
      "          -0.9682,  1.2769, -0.8630,  0.9748, -1.1150,  1.2158, -0.5397,\n",
      "           1.1453, -0.7229, -1.0099, -0.5638,  1.0680, -0.9121,  1.1088,\n",
      "          -0.9510, -1.0410, -0.6462,  1.2293, -0.8961,  1.0997, -0.9620,\n",
      "           0.6755, -0.9179,  1.1101, -1.0207,  1.0406, -0.9958,  1.3474,\n",
      "          -0.8335,  1.1736, -0.7036,  0.9449, -1.1703,  1.5556, -0.8966,\n",
      "           1.1613, -1.3236,  1.0681, -0.8874, -0.9121, -1.4174,  1.4467,\n",
      "          -0.7600,  1.1488, -1.0856,  1.3024, -0.9631,  1.0015, -0.8097,\n",
      "           0.9732, -0.9282,  0.9199, -0.9078,  1.0995, -0.8588, -0.9967,\n",
      "          -0.8009,  1.0681, -1.0619,  1.0736, -1.0720,  0.9986, -1.0238,\n",
      "          -0.7883, -0.9551,  0.9874, -0.9693,  0.9707, -0.7201,  1.1398,\n",
      "          -0.6912,  1.2439, -0.7502,  1.0697, -0.9614,  1.1220, -0.9113,\n",
      "           1.4544, -1.0177, -0.9438, -0.7280,  1.4422, -0.5959,  0.8086,\n",
      "          -1.3291,  1.3384, -0.6397,  0.9564, -1.0130,  1.1647, -0.9535,\n",
      "           1.1500, -0.8030,  1.0119, -0.8852,  1.0613, -0.6862,  1.0654,\n",
      "          -1.2070,  1.0496, -0.6911,  1.4989, -0.8058,  0.9854, -1.0723,\n",
      "           1.0624, -0.7912, -0.9121, -1.1118,  0.7902, -0.8889,  1.0268,\n",
      "          -1.0211,  1.2278, -1.1964,  1.4079, -0.9198,  1.1654, -1.2412,\n",
      "           0.8195, -0.8757,  1.2152, -0.7283,  0.8945, -0.8979,  1.0911,\n",
      "          -0.8511,  1.2687, -0.7912, -0.9284, -0.9121,  1.0683, -0.9780,\n",
      "           0.9723]]]), 'gloss_feature_norm': tensor([[[-0.0489,  0.0577, -0.0471,  0.0524, -0.0400,  0.0441, -0.0275,\n",
      "           0.0472, -0.0403,  0.0552, -0.0403,  0.0481, -0.0509,  0.0478,\n",
      "          -0.0408, -0.0441, -0.0451,  0.0503, -0.0387,  0.0482, -0.0457,\n",
      "           0.0447, -0.0441,  0.0487, -0.0487, -0.0363, -0.0417,  0.0464,\n",
      "          -0.0389,  0.0501, -0.0442,  0.0519, -0.0466,  0.0480, -0.0317,\n",
      "           0.0472, -0.0472,  0.0435, -0.0299,  0.0479, -0.0317,  0.0495,\n",
      "          -0.0360,  0.0411, -0.0295,  0.0597, -0.0412,  0.0528, -0.0376,\n",
      "           0.0492, -0.0345,  0.0360, -0.0439,  0.0513, -0.0408,  0.0482,\n",
      "          -0.0472, -0.0453, -0.0527,  0.0309, -0.0420,  0.0497, -0.0394,\n",
      "           0.0460, -0.0373,  0.0472, -0.0433,  0.0483, -0.0395,  0.0415,\n",
      "          -0.0538,  0.0474, -0.0403,  0.0444, -0.0479,  0.0486, -0.0423,\n",
      "           0.0483, -0.0403,  0.0472, -0.0403,  0.0599, -0.0286,  0.0423,\n",
      "          -0.0307,  0.0491, -0.0399,  0.0455, -0.0407, -0.0340, -0.0295,\n",
      "           0.0482, -0.0324,  0.0384, -0.0424,  0.0480, -0.0463, -0.0417,\n",
      "          -0.0489,  0.0444, -0.0418,  0.0472, -0.0307,  0.0482, -0.0420,\n",
      "           0.0475, -0.0430,  0.0406, -0.0430,  0.0431, -0.0380,  0.0570,\n",
      "          -0.0356,  0.0410, -0.0271, -0.0328, -0.0377,  0.0395, -0.0381,\n",
      "           0.0535, -0.0394,  0.0530, -0.0420,  0.0533, -0.0448,  0.0472,\n",
      "          -0.0263,  0.0452, -0.0385,  0.0429, -0.0407,  0.0570, -0.0409,\n",
      "           0.0477, -0.0491,  0.0530, -0.0389,  0.0532, -0.0403,  0.0457,\n",
      "          -0.0278,  0.0519, -0.0345,  0.0530, -0.0399,  0.0499, -0.0419,\n",
      "           0.0496, -0.0446,  0.0473, -0.0373,  0.0491, -0.0381,  0.0491,\n",
      "          -0.0352,  0.0499, -0.0418,  0.0548, -0.0550,  0.0522, -0.0401,\n",
      "           0.0521, -0.0457,  0.0480, -0.0466,  0.0320, -0.0322, -0.0278,\n",
      "          -0.0519,  0.0495, -0.0346,  0.0442, -0.0403,  0.0429, -0.0582,\n",
      "           0.0439, -0.0280,  0.0512, -0.0470,  0.0472, -0.0403,  0.0447,\n",
      "          -0.0398,  0.0467, -0.0338,  0.0492, -0.0449,  0.0596, -0.0391,\n",
      "           0.0349, -0.0402,  0.0570, -0.0513, -0.0373, -0.0423,  0.0483,\n",
      "          -0.0440,  0.0496, -0.0394,  0.0455, -0.0302,  0.0472, -0.0448,\n",
      "           0.0499, -0.0528,  0.0450, -0.0496,  0.0473, -0.0332,  0.0392,\n",
      "          -0.0410,  0.0289, -0.0398,  0.0428, -0.0287,  0.0465, -0.0280,\n",
      "           0.0474, -0.0448,  0.0446, -0.0364,  0.0471, -0.0374,  0.0294,\n",
      "          -0.0498,  0.0522, -0.0292, -0.0405, -0.0438,  0.0367, -0.0284,\n",
      "           0.0407, -0.0495,  0.0495, -0.0367,  0.0526, -0.0274,  0.0583,\n",
      "          -0.0337,  0.0606, -0.0402, -0.0389, -0.0326,  0.0432, -0.0396,\n",
      "           0.0470, -0.0492,  0.0397, -0.0470,  0.0400, -0.0358,  0.0594,\n",
      "          -0.0279,  0.0485, -0.0273,  0.0415, -0.0449,  0.0449, -0.0436,\n",
      "           0.0534, -0.0437,  0.0641, -0.0396,  0.0468, -0.0441,  0.0349,\n",
      "          -0.0316,  0.0460, -0.0399, -0.0255, -0.0448,  0.0472, -0.0286,\n",
      "           0.0433, -0.0393,  0.0515, -0.0552,  0.0478, -0.0375,  0.0487,\n",
      "          -0.0491, -0.0360, -0.0446,  0.0487, -0.0353,  0.0424, -0.0400,\n",
      "           0.0415, -0.0383,  0.0485, -0.0403,  0.0427, -0.0374,  0.0397,\n",
      "          -0.0376,  0.0553, -0.0403,  0.0491, -0.0549,  0.0498, -0.0368,\n",
      "           0.0548, -0.0381,  0.0491, -0.0474,  0.0259, -0.0331,  0.0517,\n",
      "          -0.0403,  0.0366, -0.0244,  0.0594, -0.0344,  0.0402, -0.0379,\n",
      "           0.0527, -0.0403,  0.0470, -0.0377,  0.0500, -0.0386,  0.0456,\n",
      "          -0.0318,  0.0471, -0.0502,  0.0467, -0.0377, -0.0375, -0.0342,\n",
      "           0.0501, -0.0324,  0.0477, -0.0245, -0.0391, -0.0433,  0.0524,\n",
      "          -0.0403,  0.0584, -0.0310,  0.0447, -0.0292, -0.0309, -0.0334,\n",
      "           0.0560, -0.0315,  0.0452, -0.0356,  0.0377, -0.0419,  0.0632,\n",
      "          -0.0281,  0.0701, -0.0434,  0.0474, -0.0482, -0.0348, -0.0403,\n",
      "           0.0572, -0.0416,  0.0481, -0.0394,  0.0515, -0.0403,  0.0472,\n",
      "          -0.0297,  0.0396, -0.0231, -0.0403, -0.0493,  0.0470, -0.0370,\n",
      "           0.0483, -0.0255,  0.0431, -0.0508,  0.0540, -0.0259,  0.0509,\n",
      "          -0.0428,  0.0564, -0.0381,  0.0431, -0.0493,  0.0537, -0.0239,\n",
      "           0.0506, -0.0319, -0.0446, -0.0249,  0.0472, -0.0403,  0.0490,\n",
      "          -0.0420, -0.0460, -0.0286,  0.0543, -0.0396,  0.0486, -0.0425,\n",
      "           0.0299, -0.0406,  0.0491, -0.0451,  0.0460, -0.0440,  0.0595,\n",
      "          -0.0368,  0.0519, -0.0311,  0.0418, -0.0517,  0.0687, -0.0396,\n",
      "           0.0513, -0.0585,  0.0472, -0.0392, -0.0403, -0.0626,  0.0639,\n",
      "          -0.0336,  0.0508, -0.0480,  0.0576, -0.0426,  0.0443, -0.0358,\n",
      "           0.0430, -0.0410,  0.0407, -0.0401,  0.0486, -0.0380, -0.0440,\n",
      "          -0.0354,  0.0472, -0.0469,  0.0474, -0.0474,  0.0441, -0.0452,\n",
      "          -0.0348, -0.0422,  0.0436, -0.0428,  0.0429, -0.0318,  0.0504,\n",
      "          -0.0305,  0.0550, -0.0332,  0.0473, -0.0425,  0.0496, -0.0403,\n",
      "           0.0643, -0.0450, -0.0417, -0.0322,  0.0637, -0.0263,  0.0357,\n",
      "          -0.0587,  0.0592, -0.0283,  0.0423, -0.0448,  0.0515, -0.0421,\n",
      "           0.0508, -0.0355,  0.0447, -0.0391,  0.0469, -0.0303,  0.0471,\n",
      "          -0.0533,  0.0464, -0.0305,  0.0662, -0.0356,  0.0435, -0.0474,\n",
      "           0.0469, -0.0350, -0.0403, -0.0491,  0.0349, -0.0393,  0.0454,\n",
      "          -0.0451,  0.0543, -0.0529,  0.0622, -0.0407,  0.0515, -0.0549,\n",
      "           0.0362, -0.0387,  0.0537, -0.0322,  0.0395, -0.0397,  0.0482,\n",
      "          -0.0376,  0.0561, -0.0350, -0.0410, -0.0403,  0.0472, -0.0432,\n",
      "           0.0430]]]), 'gloss_logits': tensor([[[-0.3358, -0.7809,  0.2000,  ..., -0.4629,  1.1827,  0.1175]]]), 'gloss_probabilities_log': tensor([[[-8.0975, -8.5427, -7.5618,  ..., -8.2247, -6.5791, -7.6442]]]), 'gloss_probabilities': tensor([[[0.0003, 0.0002, 0.0005,  ..., 0.0003, 0.0014, 0.0005]]]), 'valid_len_out': None}\n"
     ]
    }
   ],
   "source": [
    "## We test the pretrained S3D model on a video from the CorpusNGT dataset, and it indeed works.\n",
    "\n",
    "def transform(snippet):\n",
    "    ''' stack & noralization '''\n",
    "    snippet = np.concatenate(snippet, axis=-1)\n",
    "    snippet = torch.from_numpy(snippet).permute(2, 0, 1).contiguous().float()\n",
    "    snippet = snippet.mul_(2.).sub_(255).div(255)\n",
    "    snippet = snippet.view(1,-1,3,snippet.size(1),snippet.size(2)).permute(0,2,1,3,4) \n",
    "    print(snippet.shape)\n",
    "    return snippet\n",
    "    # returns tensor in size [batch, channels, frames, height, width]\n",
    "    # all values normalized\n",
    "\n",
    "def main():\n",
    "    ''' Output the top 5 Kinetics classes predicted by the model or the gloss features'''\n",
    "    \n",
    "    #path_sample = './sample'\n",
    "    path_sample = 'Data/CorpusNGT/gloss_split/WINNEN/9'\n",
    "    \n",
    "    #file_weight = 'SLRT-NGT/TwoStreamNetwork/pretrained_models/s3ds_glosscls_ckpt/epoch299.pth.tar'\n",
    "    file_weight = 'SLRT-NGT/TwoStreamNetwork/pretrained_models/csl-daily_s2g/ckpts/best.ckpt'\n",
    "    #file_weight = 'SLRT-NGT/TwoStreamNetwork/pretrained_models/s3ds_actioncls_ckpt/S3D_kinetics400.pt'\n",
    "    \n",
    "    class_names = pd.read_pickle(\"SLRT-NGT/TwoStreamNetwork/data/csl-daily/gloss2ids.pkl\")\n",
    "    class_names = {K-4:V for (V,K) in [x for x in class_names.items()][4:]}\n",
    "    #class_names = pd.read_csv(\"Data/Kinetics_labels/kinetics_400_labels.csv\")\n",
    "    \n",
    "    num_class = len(class_names)\n",
    "    print(\"Number of classes: \" + str(num_class))\n",
    "    #num_class = 400\n",
    "\n",
    "    state = \"features\"\n",
    "    #state = \"kinetics\"\n",
    "\n",
    "\n",
    "    ### Perform S3D feature extraction\n",
    "    model = S3Ds(num_class, use_block=4, freeze_block=1)  ## 4 and 1 for gloss\n",
    "\n",
    "    # load the weight file and copy the parameters\n",
    "    if os.path.isfile(file_weight):\n",
    "        print ('loading weight file')\n",
    "        weight_dict = torch.load(file_weight)\n",
    "        model_dict = model.state_dict()\n",
    "        for name, param in weight_dict.items(): # name is the name of the module, param is the weights\n",
    "            #print(\"NAME \" + name)\n",
    "            #print(param.shape)\n",
    "            #print(param)\n",
    "            if 'module' in name:\n",
    "                name = '.'.join(name.split('.')[1:])\n",
    "            if name in model_dict:\n",
    "                if param.size() == model_dict[name].size():\n",
    "                    model_dict[name].copy_(param)\n",
    "                else:\n",
    "                    print (' size? ' + name, param.size(), model_dict[name].size())\n",
    "            else:\n",
    "                print (' name? ' + name)\n",
    "\n",
    "        print (' loaded')\n",
    "    else:\n",
    "        print ('weight file?')\n",
    "\n",
    "    model = model.cuda()\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    model.eval()\n",
    "\n",
    "    list_frames = [f for f in os.listdir(path_sample) if os.path.isfile(os.path.join(path_sample, f)) and f.split(\".\")[1] == \"jpg\"]\n",
    "    list_frames.sort()\n",
    "\n",
    "    # read all the frames of sample clip\n",
    "    snippet = []\n",
    "    for frame in list_frames:\n",
    "        img = cv2.imread(os.path.join(path_sample, frame))\n",
    "        img = cv2.resize(img, [270, 270])\n",
    "        img = img[...,::-1]\n",
    "        snippet.append(img)\n",
    "        #snippet.append(img) ## added because not enough frames in test\n",
    "\n",
    "    clip = transform(snippet)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(clip.cuda()).cpu().data#[0]\n",
    "\n",
    "    if state == \"features\":\n",
    "        #print(logits)\n",
    "        print ('\\nThe features outputted by pretrained S3D')\n",
    "        print(logits)\n",
    "\n",
    "    if state == \"kinetics\":\n",
    "        preds = torch.softmax(logits, 0).numpy()\n",
    "        sorted_indices = np.argsort(preds)[::-1][:5]\n",
    "        print(sorted_indices)\n",
    "        print(logits.shape)\n",
    "        print ('\\nTop 5 kinetics classes ... with probability')\n",
    "        for idx in sorted_indices:\n",
    "            #print(class_names['name'][idx], '...', preds[idx])\n",
    "            print(class_names[idx], '...', preds[idx])\n",
    "\n",
    "\n",
    "    ### Perform Visual Head feature extraction\n",
    "    #file_weight_vh = 'SLRT-NGT/TwoStreamNetwork/pretrained_models/csl-daily_s2g/ckpts/best.ckpt'\n",
    "    model = VisualHead(cls_num=num_class, pe=True)  ## 4 and 1 for gloss    #pretrained_ckpt=file_weight_vh\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #print(split_data[3]['sign'])\n",
    "        #features = model(x=split_data[3]['sign'].unsqueeze(0), mask=torch.zeros(1))  \n",
    "        features = model(x=logits.unsqueeze(0), mask=torch.zeros(1))  \n",
    "        print(\"\\n\")\n",
    "        print(features['gloss_feature'].shape)\n",
    "        print(features['gloss_probabilities'].shape)\n",
    "        print(features)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57da89-73f6-4b0a-9fec-040cad7dbaf6",
   "metadata": {},
   "source": [
    "## Classification S2G Test\n",
    "\n",
    "So the pretrained S3D and visual head work, so we can use these to extract the features for all the CorpusNGT data\n",
    "We can choose to then use either the visual features exported by the S3D, the gloss representations outputted by the VisualHead, or the gloss logits or gloss probabilities which have been classified and then softmaxed. Either way, this is the S3D is the 'cold' part of the model; we don't further train these weights. The VisualHead plus Classifier do not use pretrained weights, so if we are training for S2G this is the 'hot' part that would be trained. \n",
    "\n",
    "Next steps:\n",
    "- Test to see if a the VisualHead and Classifier trained on CorpusNGT acchieve good performance\n",
    "- See if this performance gets even better when using Mediapipe data alongside the S3D features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283e28ca-4663-428a-91a5-2c5e2109d564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8cfc4-cf00-45f7-a12a-4f2ab7acf4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
